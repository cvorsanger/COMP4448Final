{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center style=\"font-size:48px;\">Clean Up</center>\n",
    "<br>\n",
    "Steps needed to clean the data and create useful features to use in our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('../Data/car-assignments.csv')\n",
    "cc = pd.read_csv('../Data/cc_data.csv', encoding='cp1252', parse_dates=['timestamp'])\n",
    "gps = pd.read_csv('../Data/gps.csv', parse_dates=['Timestamp'])\n",
    "loyalty = pd.read_csv('../Data/loyalty_data.csv', encoding='cp1252', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isWeekend(x):\n",
    "    # Finds if a day is a weekend\n",
    "    if x.weekday() >= 5:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def seperateTimeUnits(df, col):\n",
    "    # Lets Seperate the variable time units into their own features\n",
    "    units = ['day', 'hour', 'minute', 'second']\n",
    "    for unit in units:\n",
    "        if unit == 'day':\n",
    "            df[unit] = df[col].apply(lambda x: x.day)\n",
    "        if unit == 'hour':\n",
    "            df[unit] = df[col].apply(lambda x: x.hour)\n",
    "        if unit == 'minute':\n",
    "            df[unit] = df[col].apply(lambda x: x.minute)\n",
    "        if unit == 'second':\n",
    "            df[unit] = df[col].apply(lambda x: x.second)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the gps and the car assignment data frames. Do a left outer join with gos being the left dataframe. This will keep the gps points for the truck drivers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = gps.merge(cars, left_on='id', right_on='CarID', how='left')\n",
    "locations.drop(columns='CarID', inplace =True)\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the gps data for the truck drivers the names are null. Lets fill that with the name \"Truck Driver_X\" where \"X\" is the CarID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['CurrentEmploymentType'] = locations['CurrentEmploymentType'].fillna('Facilities')\n",
    "locations['CurrentEmploymentTitle'] = locations['CurrentEmploymentTitle'].fillna('Truck Driver')\n",
    "locations['LastName'] = locations['LastName'].fillna('Driver')\n",
    "locations['FirstName'] = locations['FirstName'].fillna('Truck')\n",
    "locations['LastName'] = locations.apply(lambda x: 'Driver_{}'.format(x['id']) if x['LastName'] == 'Driver' else x['LastName'], axis =1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Seperate the varibale time units into their own features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = seperateTimeUnits(locations, 'Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shrink data size (so we can put it on github) downsample the data to 1minute, take the median of any duplicate location data (by person and time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = locations.groupby(['FirstName', 'LastName', 'CurrentEmploymentType','CurrentEmploymentTitle']) \\\n",
    "    .resample(rule='1min', on='Timestamp') \\\n",
    "    .median() \\\n",
    "    .reset_index() \\\n",
    "    .dropna() \\\n",
    "    .drop(columns = 'second')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a feature denoting if a day is the weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations['Weekend'] = locations.apply(lambda x: isWeekend(x['Timestamp']), axis = 1)\n",
    "locations.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now a useable set of data for our analysis. We can subset by Name, Job Title, Job Type, Car, day, time of day, and weekend. We can also resample to get a datapoint per 5, 10, 15, etc. minute intervals for ur desired subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purchase Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Is Loyalty variable that denotes if a purchase is a loyalty card purchase or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc['Is_Loyalty'] = False\n",
    "loyalty['Is_Loyalty'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the locaton data lets seperate the time units and create a weekend variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Seperate the varibale time units into their own features\n",
    "cc = seperateTimeUnits(cc, 'timestamp')\n",
    "loyalty = seperateTimeUnits(loyalty, 'timestamp')\n",
    "# Deontate Weekends\n",
    "cc['Weekend'] = cc.apply(lambda x: isWeekend(x['timestamp']), axis = 1)\n",
    "loyalty['Weekend'] = loyalty.apply(lambda x: isWeekend(x['timestamp']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find which transactions are duplicates (at least most of them) by a person's name, purchase location, purchase day, and the cents in the price. The loyalty purchase price is less prone to outliers so we will use that as the final purchase price. The timestamp in the credit card dataframe has more infirmation on time of purchase so we will use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the cents from the purcahase price\n",
    "cc['cents'] = round(cc.apply(lambda x: (x['price'] % 1) * 100,  axis = 1))\n",
    "loyalty['cents'] = round(loyalty.apply(lambda x: (x['price'] % 1) * 100,  axis = 1))\n",
    "# Loop to match the duplicate purchases. Overwrite the CREDIT CARD dataframe with tthe loyalty price and loyalty card flag values\n",
    "for index, row in cc.iterrows():\n",
    "    first = row['FirstName']\n",
    "    last = row['LastName']\n",
    "    location = row['location']\n",
    "    day = row['day']\n",
    "    cents = row['cents']\n",
    "    temp = loyalty[loyalty.FirstName == first]\n",
    "    temp = temp[temp.LastName == last]\n",
    "    temp = temp[temp.location == location]\n",
    "    temp = temp[temp.day == day]\n",
    "    temp = temp[temp.cents == cents]\n",
    "    if len(temp) >= 1:\n",
    "        cc.loc[index, 'Is_Loyalty'] = True\n",
    "        cc.loc[index, 'price'] = temp.price.values\n",
    "\n",
    "# Merge the two dataframe by appending one to the other and dropping duplicates\n",
    "buys = pd.concat([cc, loyalty]).drop_duplicates(['FirstName', 'LastName', 'location', 'day', 'cents'], keep='first')\n",
    "buys.drop(columns  ='cents', inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also add the personal information (job title and type). Use a left outer join to not lose data for anybody who isn't in the cars dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buys = buys.merge(cars, left_on=['LastName', 'FirstName'], right_on=['LastName', 'FirstName'], how= 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the null values for job type and title with 'Other'. Also, save their carId as 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buys.fillna({'CurrentEmploymentType' : 'Other', 'CurrentEmploymentTitle':'Other'}, inplace= True)\n",
    "def CarNulls(x):\n",
    "    if pd.isna(x['CarID']):\n",
    "        if x['CurrentEmploymentTitle'] == 'Truck Driver':\n",
    "            return 100\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return x['CarID']\n",
    "\n",
    "buys['CarID'] = buys.apply(lambda x: CarNulls(x), axis =1)\n",
    "buys.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.to_csv('../CheckPoints/Locations_Clean.csv')\n",
    "buys.to_csv('../CheckPoints/Buys_Clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span  style=\"width:600px;display:inline-block;text-align:left\">\n",
    "        <a href=\"./FurtherEDA.ipynb\">&#60;&#60;Further Exploratoy Data Analysis</a>\n",
    "    </span>\n",
    "    <span style=\"width:600px;display:inline-block;text-align:right\">\n",
    "        <a href=\"./Modeling.ipynb\">Modeling&#62;&#62;</a>\n",
    "    </span>\n",
    "</div>\n",
    "<div>\n",
    "    <center>\n",
    "        <span style=\"width:200px;display:inline-block;text-align:center\">\n",
    "            <a href=\"./Master.ipynb\">Master Notebook</a>\n",
    "        </span>\n",
    "        <span style=\"width:200px;display:inline-block;text-align:center\">\n",
    "            <a href=\"../README.md\">Table of Contents</a>\n",
    "        </span>\n",
    "    </center>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbc5d808ed13306b281beb3b148e89003940376baf375861433a5e62b978e9c3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
